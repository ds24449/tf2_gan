{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN and TF2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNggfeGpkf69l5hUq1ylyc+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ds24449/tf2_gan/blob/main/GAN_and_TF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAWEynvYBmW-"
      },
      "source": [
        "## What are GANs?\n",
        "[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (GANs) are one of the most interesting ideas in computer science today. Two models are trained simultaneously by an adversarial process. A *generator* (\"the artist\") learns to create images that look real, while a *discriminator* (\"the art critic\") learns to tell real images apart from fakes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTRN2F0qc3gg"
      },
      "source": [
        "##Here I am going to use TensorFlow to implement DCGAN and WGAN\n",
        "GAN is basically a game between Generator and Dicriminator. Generator has to Maximize the Loss and Discriminator has to minimize this loss.\n",
        "\n",
        "I am going to Use MNIST digit dataset.\n",
        "\n",
        "![sample output](https://tensorflow.org/images/gan/dcgan.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKewzIPPg7Ay"
      },
      "source": [
        "#Lets Import our good friend TensorFlow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import PIL\n",
        "import imageio #for I/O ops on image data [to generate gifs!!]\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnqjpCeLdhvE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "401z4YBHionA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a59aad9-171b-47db-eb3b-ed447380985f"
      },
      "source": [
        "(X_train,Y_train),(_,_) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1).astype('float32') ##Adding a channels dimension\n",
        "# X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1).astype('float32')\n",
        "print('MNIST Dataset Shape:')\n",
        "print('X_train: ' + str(X_train.shape))\n",
        "print('Y_train: ' + str(Y_train.shape))\n",
        "# print('X_test:  '  + str(X_test.shape))\n",
        "# print('Y_test:  '  + str(Y_test.shape))\n",
        "X_train = X_train/255."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "MNIST Dataset Shape:\n",
            "X_train: (60000, 28, 28, 1)\n",
            "Y_train: (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD7KW3cXJgaz"
      },
      "source": [
        "##Remember Here\n",
        "Do study more about what are BatchDatset objects and how to access whats inside them(is there a way without iterators?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmle4e09jRGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e51b5a-0104-4845-8a8e-06d7ca1e296d"
      },
      "source": [
        "#Batch and Shuffle Data\n",
        "BATCH_SIZE = 128\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(X_train.shape[0]).batch(BATCH_SIZE)\n",
        "print(type(train_dataset))\n",
        "print(train_dataset.__len__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
            "<bound method DatasetV2.__len__ of <BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gdRN92yJxN0"
      },
      "source": [
        "#Create Models \n",
        "Both Generator and Discriminator are built using Keras API\n",
        "\n",
        "##Generator Model :- \n",
        "Generator is a Upsampler which takes a Noise vector and produces a sensible(to us) image.\n",
        "\n",
        "We use a Dense Layer to Take input noise vector and thne upsample it to a size of [28,28,1] i.e to the size of an image in MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0gCUFNZCZLT"
      },
      "source": [
        "def get_generator_model():\n",
        "  \"\"\"Returns A Genreator Model \n",
        "  \n",
        "    Upsample Images from vector to a tensor of shape (28,28,1)\n",
        "  \"\"\"\n",
        "  model = Sequential([\n",
        "      layers.Dense(7*7*256,use_bias=False,input_shape=(100,)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "\n",
        "      layers.Reshape(target_shape=(7,7,256)),\n",
        "\n",
        "      #real upsampling starts here\n",
        "      layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding=\"same\",use_bias=False),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "\n",
        "      layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding=\"same\",use_bias=False),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Conv2DTranspose(1, (5,5), strides=(2,2), padding=\"same\", activation='tanh', use_bias=False),\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "GGdTEpPPRD1A",
        "outputId": "f3c0e835-d12a-4461-ce83-7141b8eeb09f"
      },
      "source": [
        "gen = get_generator_model()\n",
        "gen.summary()\n",
        "noise = tf.random.normal([1,100])\n",
        "\n",
        "generated_image = gen(noise,training = False)\n",
        "plt.imshow(generated_image[0,:,:,0],cmap='gray')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12544)             1254400   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
            "=================================================================\n",
            "Total params: 2,330,944\n",
            "Trainable params: 2,305,472\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f58a02abc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XRXXdRqhbCB"
      },
      "source": [
        "##The Discriminator\n",
        "It is a CNN based Classification model\n",
        "Classifies between Real and Fake"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRl_kIlQRwJ0"
      },
      "source": [
        "def get_discriminator_model():\n",
        "  \"\"\" Discrimiator\n",
        "  If no activation is defined at Dense layer then Negative value for fakes \n",
        "  and positive for Real\n",
        "  \"\"\"\n",
        "  model = Sequential([\n",
        "      layers.Conv2D(64,(5,5),padding = \"valid\",input_shape=[28,28,1]),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.45),\n",
        "      layers.Conv2D(128,(5,5),padding = \"valid\",input_shape=[28,28,1]),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.45),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(1),\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0foqNMajJcT",
        "outputId": "39cb2ac1-4d61-4e8b-89cc-66b20be372f5"
      },
      "source": [
        "disc = get_discriminator_model()\n",
        "disc.summary()\n",
        "print(\"------------------------\")\n",
        "print(disc(generated_image))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 20, 20, 128)       204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51201     \n",
            "=================================================================\n",
            "Total params: 257,793\n",
            "Trainable params: 257,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "------------------------\n",
            "tf.Tensor([[-0.00112904]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVbHoNQSpbkW"
      },
      "source": [
        "###Base Loss Function for Disc and Gen\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tcp1m_Ljan4"
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "##Optimizer is the same all mighty Adam Optimizer\n",
        "gen_opt = tf.keras.optimizers.Adam()\n",
        "disc_opt = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v2T0scQp9Wg"
      },
      "source": [
        "###Discriminator Loss\n",
        "this loss is combined loss of discriminators performance on Real images and on fake images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB_8zEUSp8wm"
      },
      "source": [
        "def discriminator_loss(real_output,fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n",
        "  return real_loss+fake_loss\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g6lZC6uqudE"
      },
      "source": [
        "###Gen Loss\n",
        "how well the generator is able to fool the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLL-5vfaqnXf"
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output),fake_output)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTWqiOD6rRoG"
      },
      "source": [
        "# checkpoint_dir = './training_checkpoints'\n",
        "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "# checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "#                                  discriminator_optimizer=discriminator_optimizer,\n",
        "#                                  generator=generator,\n",
        "#                                  discriminator=discriminator)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-J-52ECr3gq"
      },
      "source": [
        "###Defining Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6soVWUTru9Y"
      },
      "source": [
        "EPOCHS = 3\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKC9TWzNr-1e"
      },
      "source": [
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozo9odOpyXfK"
      },
      "source": [
        "### The Decorator @tf.function\n",
        "is used create a graph from defined function\n",
        "https://www.tensorflow.org/guide/intro_to_graphs#tracing_graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oZwZTwXr7K1"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([BATCH_SIZE,noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n",
        "    fake_image = gen(noise,training=True)\n",
        "\n",
        "    real_output = disc(images,training=True)\n",
        "    fake_output = disc(fake_image,training=True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output,fake_output)\n",
        "  #Now we calculate the loss using GradientTapes\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss,gen.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss,disc.trainable_variables)\n",
        "  #Optimize the variables with grads\n",
        "  gen_opt.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
        "  disc_opt.apply_gradients(zip(gradients_of_discriminator, disc.trainable_variables))\n",
        "\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFNqA6vx06dJ"
      },
      "source": [
        "def train(dataset,epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "    generate_and_print(gen,noise,epochs+1)\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jusgICh2UNA"
      },
      "source": [
        "Generate and print images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5CfbvPQ2U_x"
      },
      "source": [
        "def generate_and_print(model, test_input, epoch):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  # plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "qJBnkcAE4Y9n",
        "outputId": "4ed0dbaf-35b4-4c3b-c41a-baaeee9a4027"
      },
      "source": [
        "train(train_dataset,EPOCHS)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 1 is 40.169257164001465 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 2 is 40.19777989387512 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 3 is 40.43869209289551 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkCPj3wK4liu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}